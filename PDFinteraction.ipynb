{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f41862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installing required libraries:\n",
    "!pip install PyPDF2 openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c561eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported required libraries:\n",
    "import os \n",
    "import openai\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038a1a7",
   "metadata": {},
   "source": [
    "### Loading openai API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e79d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e816067",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'ds sample resumes'\n",
    "pdf_files = [file for file in os.listdir(folder_path) if file.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3b1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract text document from pdf files:\n",
    "def text_extraction(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:  #to open file in 'rb' mode i.e., read binary\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):  \n",
    "            page = pdf_reader.pages[page_num]  \n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e18812",
   "metadata": {},
   "source": [
    "### Converting PDFs to text enables the chatbot to understand and respond to user queries effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a4b7d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of associate-data-scientist-resume-example.pdf:\n",
      "AMBROSE\n",
      "HORVÁTH\n",
      "Associate Data Scientist\n",
      "Ambro_@email.com\n",
      "(123) 456-7890\n",
      "Santa Barbara, CA\n",
      "LinkedIn\n",
      "facebook\n",
      "twitter\n",
      "EDUCATION\n",
      "B.S.\n",
      "Computer Science\n",
      "Pepperdine University\n",
      "2017 - 2021\n",
      "Santa Barbara, CA\n",
      "GPA: 4.0\n",
      "SKILLS\n",
      "Machine and Deep Learning\n",
      "Statistical Analysis\n",
      "Processing Large Data Sets\n",
      "Data Visualization\n",
      "Mathematics\n",
      "Programming\n",
      "Data Wrangling\n",
      "CERTIFICATIONS\n",
      "Open Certiﬁed Data\n",
      "Scientist (Open CDS)\n",
      "Google Data Machine\n",
      "LearningCAREER OBJECTIVE\n",
      "Conscientious and innovative data science Summa Cum Laude\n",
      "graduate with extensive skills and outstanding aptitude for\n",
      "learning. Seeking a challenging and career-building position at\n",
      "Northrop Grumman as an associate data scientist.\n",
      "WORK EXPERIENCE\n",
      "Data Scientist Intern\n",
      "County of Ventura\n",
      "2020 - current Ventura, CA\n",
      "Designed and implemented over 40 machine-learning\n",
      "models for different programs and projects\n",
      "Veriﬁed results of algorithms to predict future occurrences\n",
      "using real-world programs data with 82% precision\n",
      "Extracted raw data from Twitter APIs and analyzed tweets to\n",
      "generate analysis showing trends in public opinion\n",
      "regarding policy changes\n",
      "Developed a Java application that performed pattern\n",
      "analysis of criminal incidents to help identify and visualize\n",
      "hotspots (vulnerable areas) in the city\n",
      "PROJECTS\n",
      "Image Caption Generator Project in Python\n",
      "Pepperdine - Senior Project\n",
      "Aug 2021 - Dec 2021\n",
      "Designed and created an 2 applications to analyze images\n",
      "and convert to natural language (English) descriptions\n",
      "Utilized deep learning techniques to implement a\n",
      "convolutional neural network (CNN) with recurrent neural\n",
      "network (LSTM) to build the image caption generator\n",
      "Created application in Python using a Keras framework\n",
      "against a Flickr 8K dataset\n",
      "Credit Card Fraud Detection Project\n",
      "Pepperdine - Junior Project\n",
      "Aug 2020 - Jun 2021\n",
      "Created 2 apps that classiﬁed credit card transactions into\n",
      "fraudulent and genuine, ﬁt the models, and plotted\n",
      "performance curves\n",
      "Used R with algorithms such as Decision Trees, Logistic\n",
      "Regression, Artiﬁcial Neural Networks, and Gradient\n",
      "Boosting Classiﬁer\n",
      "Created application in R against 6 credit card transaction\n",
      "databases\n",
      "\n",
      "Contents of data-scientist-intern-resume-example.pdf:\n",
      "YASMIN PATEL\n",
      "Data Scientist Intern\n",
      "y.patel@email.com (123) 456-7890 Cambridge, MA\n",
      "LinkedIn\n",
      "WORK EXPERIENCE\n",
      "Retail associate\n",
      "TJ Maxx\n",
      "2022 - current Cambridge, MA\n",
      "Exceeded monthly sales targets by 22%, contributing to the\n",
      "store's recognition as a top-performing location.\n",
      "Updated store layouts to increase customer engagement with\n",
      "featured products by 48%.\n",
      "Recognized by management for providing exceptional service\n",
      "after earning an average customer satisfaction rating of 93%.\n",
      "Conducted regular stock checks using inventory management\n",
      "systems, which minimized out-of-stock incidents by 29%.\n",
      "PROJECTS\n",
      "Library assistant\n",
      "Harvard University\n",
      "2022\n",
      "Recommended personalized book titles to library patrons that\n",
      "led to 89% satisfaction ratings.\n",
      "Collaborated with local nonproﬁts to host literacy initiatives,\n",
      "growing participation by 28% per month.\n",
      "Designed captivating book displays that boosted checkouts in\n",
      "promoted genres by 47%.\n",
      "Developed a book tracking system with SQLite to improve\n",
      "cataloging accuracy, reducing data entry errors by 31%.\n",
      "Event staﬀ\n",
      "Harvard University\n",
      "2021\n",
      "Decorated venues for 42 campus events, earning an average\n",
      "satisfaction rating of 4.8/5 from attendees.\n",
      "Engaged event attendees by actively participating in crowd\n",
      "activities, which boosted guest participation by 38%.\n",
      "Scanned 1100+ tickets per event to maintain an average wait\n",
      "time of under 30 seconds for guests at entry points.\n",
      "Provided exceptional guest assistance by resolving 92% of\n",
      "inquiries on the spot.OBJECTIVE\n",
      "With a strong academic background in\n",
      "computer science from Harvard\n",
      "University and eager to kickstart my\n",
      "career as a data scientist intern at\n",
      "IBM. Proﬁcient in NumPy, Scikit-learn,\n",
      "dplyr, MySQL, SQLite, and Keras with\n",
      "hope to learn from industry experts,\n",
      "tackle complex data challenges, and\n",
      "support IBM's production of cutting-\n",
      "edge technology.\n",
      "EDUCATION\n",
      "Bachelor of Science\n",
      "Retail associateComputer Science\n",
      "Harvard University\n",
      "2020 - current\n",
      "Cambridge, MA\n",
      "SKILLS\n",
      "NumPy\n",
      "Scikit-learn\n",
      "dplyr\n",
      "MySQL\n",
      "SQLite\n",
      "Keras\n",
      "\n",
      "Contents of data-scientist-resume-example.pdf:\n",
      "K A N D A C E  L O U D O R\n",
      "D A T A  S C I E N T I S T\n",
      "C O N T A C T\n",
      "kloudor@email.com\n",
      "(123) 456-7890\n",
      "Mount Laurel, NJ\n",
      "LinkedIn\n",
      "Github\n",
      "E D U C A T I O N\n",
      "B.S.\n",
      "Statistics\n",
      "Rutgers University\n",
      "September 2011 - April 2015\n",
      "New Brunswick, NJ\n",
      "S K I L L S\n",
      "Python (NumPy, Pandas,\n",
      "Scikit-learn, Keras, Flask)\n",
      "SQL (MySQL, Postgres)\n",
      "Git\n",
      "Time Series Forecasting\n",
      "Productionizing Models\n",
      "Recommendation Engines\n",
      "Customer Segmentation\n",
      "AWSW O R K  E X P E R I E N C E\n",
      "Data Scientist\n",
      "Grubhub\n",
      "June 2018 - current/Princeton, NJ\n",
      "Deployed a recommendation engine to production to\n",
      "conditionally recommend other menu items based on past order\n",
      "history, increasing average order size by 7%\n",
      "Implemented various time series forecasting techniques to\n",
      "predict surge in orders, lowering customer wait by 10 minutes\n",
      "Designed a model in a pilot to increase incentives for drivers\n",
      "during peak hours, increasing driver availability by 22%\n",
      "Led a team of 3 data scientist to model the ordering process 5\n",
      "unique ways, reported results, and made recommendations to\n",
      "increase order output by 9%\n",
      "Data Scientist\n",
      "Spectrix Analytical Services\n",
      "March 2016 - June 2018/Princeton, NJ\n",
      "Built a customer attrition random forest model that improved\n",
      "monthly retention by 12 basis points for clients likely to opt-out\n",
      "by providing relevant product features for them\n",
      "Coordinated with the product and marketing teams to determine\n",
      "what kind of client interactions resulted in maximized service\n",
      "opt-ins, increasing conversions by 18%\n",
      "Partnered with product team to create a production\n",
      "recommendation engine in Python that improved the length on-\n",
      "page for users with $225K in incremental annual revenue\n",
      "Compiled and analyzed data surrounding the prototypes for a\n",
      "prosthesis, which saved over $1M in its creation\n",
      "Entry-Level Data Analyst\n",
      "Avenica\n",
      "April 2015 - March 2016/Mount Laurel, NJ\n",
      "Collaborated with product managers to perform cohort analysis\n",
      "that identiﬁed an opportunity to reduce pricing by 21% for a\n",
      "segment of users to boost yearly revenue by $560,000\n",
      "Constructed operational reporting in Tableau to improve\n",
      "scheduling contractors, saving $90,000 in the annual budget\n",
      "Implemented a long-term pricing experiment that improved\n",
      "customer lifetime value by 23%\n",
      "Ran, submitted, and reported on monthly client enrollments,\n",
      "services opted in for, and the employees assigned to clients\n",
      "\n",
      "Contents of entry-level-data-scientist-resume-example.pdf:\n",
      "Trish Mathers\n",
      "Entry-Level Data Scientist\n",
      "Innovative and scientiﬁcally rigorous recent graduate with a signiﬁcant data\n",
      "science internship experience to bring to the table. With a team-oriented\n",
      "attitude, I am eager to contribute my abilities in quantitative modeling and\n",
      "experimentation to enhance the experience of Pinterest users around the world.tmathers@email.com\n",
      "(123) 456-7890\n",
      "Bellevue, WA\n",
      "LinkedIn\n",
      "WORK EXPERIENCE\n",
      "Niantic\n",
      "Data Scientist Intern\n",
      "Seattle, WA|April 2020 - April 2021\n",
      "·Developed a program in SAS that automated reﬁnement of linear\n",
      "regression models for speciﬁc segments of a customer base that saved\n",
      "22 hours of labor per month.\n",
      "·Received, cleaned, and prepped data from client using SAS, SQL, and\n",
      "Excel to help data scientists build marketing mix models that resulted in\n",
      "a lift in ROI of 10 basis points.\n",
      "Seattle University Tutor Center\n",
      "Statistics and Mathematics Tutor\n",
      "Seattle, WA|April 2019 - April 2020\n",
      "·Assessed students' learning to determine learning weaknesses and\n",
      "needs, successfully helping students perform 13% better in algebra, pre-\n",
      "calculus, calculus, and statistics undergraduate courses.\n",
      "·Met with 30+ students per week through online learning platforms or in\n",
      "a 1:1 setting at the tutor center.\n",
      "·Scheduled weekly appointments for students, and set schedules for\n",
      "student statistics and math tutors.\n",
      "·Communicated with professors about curriculum, and submitted reports\n",
      "2 times per week to maintain up-to-date learning plans for students.\n",
      "PROJECTS\n",
      "Fantasy Football Models\n",
      "·Aggregated and prepped 3 years of fantasy football projection data from\n",
      "3 independent sources into a MySQL database.\n",
      "·Created a random forest model in SAS, combining disparate sources into\n",
      "one projection that outperformed the mean absolute error of the next\n",
      "best projection by 15%.\n",
      "Entertainment Engine\n",
      "·Aggregated data from IMDB and Rotten Tomatoes, and used k-nearest-\n",
      "neighbors in SAS, constructing an enhanced entertainment selection\n",
      "targeted to reach 15- to 25-year-olds.\n",
      "·Improved methodologies to save an average of 12 minutes per movie\n",
      "selection and 3 minutes per song selection.SKILLS\n",
      "·Programming: SAS (base\n",
      "SAS and Macros), SQL\n",
      "·Supervised Learning: linear\n",
      "and logistic regressions,\n",
      "decision trees, support\n",
      "vector machines (SVM)\n",
      "·Unsupervised Learning: k-\n",
      "means clustering, principal\n",
      "component analysis (PCA)\n",
      "·Data Visualization: Excel,\n",
      "Google Sheets\n",
      "EDUCATION\n",
      "B.S.\n",
      "Mathematics and\n",
      "Economics\n",
      "Seattle University\n",
      "September 2017 - April 2021\n",
      "Seattle, WA\n",
      "GPA: 3.7\n",
      "RELEVANT COURSES\n",
      "·Intermediate programming\n",
      "·Probability & Statistics\n",
      "·Linear Algebra\n",
      "·Applied Econometrics\n",
      "·Game Theory\n",
      "·Calculus 1-3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of senior-data-scientist-resume-example.pdf:\n",
      "Terrence Coleman\n",
      "tcoleman@email.com (123) 456-7890 Brooklyn, NY LinkedIn\n",
      "Analytically minded self-starter with a decade of experience collaborating with cross-functional teams and\n",
      "ensuring the accuracy and integrity around data and actionable insights. Prepared to lead teams and interns in\n",
      "predictive modeling and insight reporting to boost Hyphen's business efﬁciency, strategic goals, and proﬁt.\n",
      "WORK EXPERIENCE\n",
      "Best Buy-Senior Data Scientist\n",
      "October 2018 - current Remote\n",
      "·Led data extraction and evaluation efforts to save Best Buy more than 11M over the course of tenure\n",
      "·Partnered with product team to build a production recommendation engine in Python that improved the\n",
      "average length on page for users and resulted in $450K in incremental annual revenue\n",
      "·Created a customer attrition random forest model, improving monthly retention by 6 basis points for\n",
      "customers likely to attrit by servicing relevant product features for them\n",
      "·Communicated with PMs to lead 4 data scientists in project planning, development, and execution\n",
      "·Coached data team throughout short and long-term projects, redeﬁning documentation frequently\n",
      "2U-Data Scientist\n",
      "April 2014 - October 2018 Brooklyn, NY\n",
      "·Conducted A/B testing to solve client pain points in learning platforms, and identiﬁed and recommended\n",
      "solutions to solve unclear platform roadmaps, which reduced the bounce rate by 62%\n",
      "·Extracted data from 7 disparate sources, and increased agility and accuracy with a centralized system\n",
      "·Constructed decisions trees to optimize needed algorithms to better target the learning audience by 15%\n",
      "2U-Data Analyst\n",
      "April 2012 - April 2014 Brooklyn, NY\n",
      "·Determined, using Python clustering methods, groups of states where underwriting models were\n",
      "underperforming, and owned improvements to increase proﬁt by 4%\n",
      "·Identiﬁed procedural areas of improvement through customer data to help improve the proﬁtability of a\n",
      "nationwide retention program by 8%\n",
      "·Developed and owned the reporting for a nationwide retention program using Python, SQL, and Excel,\n",
      "saving an average of 60 hours of labor each month\n",
      "EDUCATION\n",
      "University of Pittsburgh -Master's ,Mathematics\n",
      "September 2012 - April 2014 Pittsburgh, PA\n",
      "University of Pittsburgh-Bachelor's,Mathematics and Economics\n",
      "September 2008 - April 2012 Pittsburgh, PA\n",
      "SKILLS\n",
      "Python (NumPy, Pandas, Scikit-learn, Flask), SAS; SQL - Redshift, MySQL; ElasticSearch; Recommendation\n",
      "Engines, Customer Segmentation & Retention Models, Price Optimization, Productionizing Models\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the PDF files and interact with GPT-3 for each extracted text\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    text = text_extraction(pdf_path)\n",
    "    print(f\"Contents of {pdf_file}:\\n{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d98eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with GPT-3\n",
    "def interact_with_gpt3(prompt, text):\n",
    "    full_prompt = f\"{prompt}\\n{text}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",  # Use the appropriate engine ID\n",
    "        prompt=full_prompt,\n",
    "        max_tokens=150,\n",
    "    )\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca2aa8",
   "metadata": {},
   "source": [
    "### Interaction with resumes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243a15cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of associate-data-scientist-resume-example.pdf:\n",
      "; Jupyter,\n",
      "Tableau\n",
      "\n",
      "The candidate has a decade of experience in data and analytics, with a focus on predictive modeling, insight reporting, and boosting business efficiency. They have also led teams of data scientists and analysts in short- and long-term projects. Additionally, the candidate has a master's degree in mathematics from the University of Pittsburgh and is skilled in Python, SAS, SQL, and recommendaton engines.\n",
      "\n",
      "Summary of data-scientist-intern-resume-example.pdf:\n",
      "Terrence Coleman is a senior data analyst with over a decade of experience in data accuracy and integrity. He is also experienced in predictive modeling and coaching data teams in project planning and execution. His skills include Python, SQL, SAS, and ElasticSearch.\n",
      "\n",
      "Summary of data-scientist-resume-example.pdf:\n",
      "Terrence Coleman is a data analyst and scientist with ten years of experience working with cross-functional teams to ensure accuracy and integrity around data and actionable insights. He is prepared to lead teams and interns in predictive modeling and insight reporting to boost Hyphen's business efficiency, strategic goals, and profit. Coleman has a Master's in Mathematics from the University of Pittsburgh and experience working with Python, SAS, SQL, and ElasticSearch. He has also developed customer segmentation and retention models, price optimization models, and production-ready models.\n",
      "\n",
      "Summary of entry-level-data-scientist-resume-example.pdf:\n",
      "\n",
      "\n",
      "Summary of senior-data-scientist-resume-example.pdf:\n",
      "The candidate has a decade of experience with data and analytics, leading teams and mentoring other data scientists. They have a Master's in Mathematics from the University of Pittsburgh and experience with Python, SAS, SQL, and Recommendation Engines.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resume Summarization\n",
    "def resume_summarization(text):\n",
    "    prompt = \"Please summarize the candidate's resume:\"\n",
    "    return interact_with_gpt3(prompt, text)\n",
    "for pdf_file in pdf_files:       # loop for taking each resume from folder\n",
    "    summary = resume_summarization(text)\n",
    "    print(f\"Summary of {pdf_file}:\\n{summary}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb0955b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screening Questions for associate-data-scientist-resume-example.pdf:\n",
      "; Tableau\n",
      "\n",
      "1. What experience do you have with predictive modeling and Insight reporting?\n",
      "2. What is your experience with leading teams and interns?\n",
      "3. What experience do you have with extracting data from disparate sources?\n",
      "4. What experience do you have with decision trees?\n",
      "5. What experience do you have with customer segmentation and retention models?\n",
      "6. What experience do you have with price optimization?\n",
      "7. What experience do you have with productionizing models?\n",
      "8. What experience do you have with Tableau?\n",
      "\n",
      "Screening Questions for data-scientist-intern-resume-example.pdf:\n",
      "1. What is your experience with data mining?\n",
      "2. What is your experience with data modeling?\n",
      "3. What is your experience with data analysis?\n",
      "4. What is your experience with artificial intelligence?\n",
      "5. What is your experience with machine learning?\n",
      "6. What is your experience with Python?\n",
      "7. What is your experience with SAS?\n",
      "8. What is your experience with SQL?\n",
      "\n",
      "Screening Questions for data-scientist-resume-example.pdf:\n",
      "__\n",
      "\n",
      "1. Can you describe your experience working with cross-functional teams?\n",
      "2. Can you describe your experience preparing and leading teams?\n",
      "3. Can you describe your experience ensuring the accuracy and integrity of data?\n",
      "4. Can you describe your experience with predictive modeling?\n",
      "5. Can you describe your experience with insight reporting?\n",
      "6. Can you describe your experience with A/B testing?\n",
      "7. Can you describe your experience with extracting data from disparate sources?\n",
      "8. Can you describe your experience with developing and owning reporting?\n",
      "9. Can you describe your experience with improving underperforming models?\n",
      "10. Can you describe your experience with segmenting customers?\n",
      "\n",
      "Screening Questions for entry-level-data-scientist-resume-example.pdf:\n",
      "1) What is your experience with leading a data team?\n",
      "2) Can you tell me about a project you led where you had to data from multiple sources?\n",
      "3) What kind of predictive modeling experience do you have?\n",
      "4) What do you know about A/B testing?\n",
      "5) Tell me about a time when you had to communicate with stakeholders about your findings.\n",
      "\n",
      "Screening Questions for senior-data-scientist-resume-example.pdf:\n",
      "1. What is your background in data?\n",
      "2. What projects have you worked on in the past?\n",
      "3. What is your experience with Python?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Candidate Screening Questions\n",
    "def candidate_screening_questions(text):\n",
    "    prompt = \"Please generate screening questions for the candidate:\"\n",
    "    return interact_with_gpt3(prompt, text)\n",
    "for pdf_file in pdf_files:\n",
    "    screening_questions = candidate_screening_questions(text)\n",
    "    print(f\"Screening Questions for {pdf_file}:\\n{screening_questions}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e34a3d2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills mentioned in associate-data-scientist-resume-example.pdf:\n",
      ", A/B\n",
      "Testing\n",
      "\n",
      "Analytical skills, self-starter, teamwork, leadership, predictive modeling, insight reporting, data extraction and evaluation, project planning and execution, A/B testing, identifying and resolving pain points, improving customer retention.\n",
      "\n",
      "Skills mentioned in data-scientist-intern-resume-example.pdf:\n",
      "Analytical skills, self-starter, leadership, data extraction, data evaluation, data analysis, A/B testing, project management, Python, SQL, Excel, SAS, price optimization, recommendation engines, customer segmentation, retention models.\n",
      "\n",
      "Skills mentioned in data-scientist-resume-example.pdf:\n",
      "analytical, self-starter,python, NumPy, Pandas, Scikit-learn, Flask, SAS, SQL, Redshift, MySQL, ElasticSearch, Recommendation Engines, Customer Segmentation & Retention Models, Price Optimization, Productionizing Models\n",
      "\n",
      "Skills mentioned in entry-level-data-scientist-resume-example.pdf:\n",
      ", A/B\n",
      "Testing, Tableau\n",
      "\n",
      "Python, SAS, SQL, Redshift, MySQL, ElasticSearch, Recommendation Engines, Customer Segmentation & Retention Models, Price Optimization, Productionizing Models, A/B Testing, Tableau\n",
      "\n",
      "Skills mentioned in senior-data-scientist-resume-example.pdf:\n",
      "Analytical skills, self-starter, experienced with cross-functional teams, data extraction and evaluation, predictive modeling, project management, A/B testing, platform optimization, centralized system development, decision tree analysis, reporting and analytics, retention program management.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def skill_extraction(text):\n",
    "    prompt = \"Please extract the skills mentioned in the resume:\"\n",
    "    return interact_with_gpt3(prompt, text)\n",
    "for pdf_file in pdf_files:\n",
    "    skills = skill_extraction(text)\n",
    "    print(f\"Skills mentioned in {pdf_file}:\\n{skills}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c2287c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated interview scheduling associate-data-scientist-resume-example.pdf:\n",
      "Hello Terrence,\n",
      "\n",
      "Thank you for expressing interest in the Data Scientist role at Hyphen.\n",
      "\n",
      "I would like to schedule an interview with you to discuss the role in further detail and to get to know you better.\n",
      "\n",
      "Would you be available for a phone call on Tuesday, January 21st at 10:00am EST?\n",
      "\n",
      "Thank you,\n",
      "\n",
      "[Your name]\n",
      "\n",
      "Generated interview scheduling data-scientist-intern-resume-example.pdf:\n",
      ", A/B Testing\n",
      "\n",
      "Hello Terrence,\n",
      "\n",
      "Thank you for your interest in the data scientist role at our company.\n",
      "\n",
      "We are impressed by your experience leading data teams and driving business efficiencies through predictive modeling and insight reporting. Your experience in retention models and price optimization will be a valuable addition to our team.\n",
      "\n",
      "We would like to invite you to interview with us at our offices in Brooklyn, NY. Please let us know what time and date would be convenient for you.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "[Your name]\n",
      "\n",
      "Generated interview scheduling data-scientist-resume-example.pdf:\n",
      ", Data\n",
      "Visualization - Tableau, Data Wrangling\n",
      "\n",
      "Hi Terrence, \n",
      "\n",
      "Thank you for expressing interest in the Data Scientist role at our company. We would love to have the opportunity to speak with you further about your experience and skills. \n",
      "\n",
      "I am available to speak with you on Monday, Tuesday, and Wednesday between 10am and 4pm EST. Please let me know if any of those times work for you or if you have any other time constraints. \n",
      "\n",
      "Best, \n",
      "\n",
      "[Your name]\n",
      "\n",
      "Generated interview scheduling entry-level-data-scientist-resume-example.pdf:\n",
      ", Tableau\n",
      "\n",
      "Hi Terrence,\n",
      "\n",
      "Thank you for expressing interest in the data scientist role at our company. We are excited to have you come in for an interview.\n",
      "\n",
      " attached is a brief overview of our company and what we do. Our data scientist role is integral in developing predictive models and insights to help guide our business decisions.\n",
      "\n",
      "Please let me know what times would work best for you to come in for an interview next week.\n",
      "\n",
      "Thank you,\n",
      "\n",
      "[Your name]\n",
      "\n",
      "Generated interview scheduling senior-data-scientist-resume-example.pdf:\n",
      "CERTIFICATIONS\n",
      "Statistical Inference, Regression Modeling, Practical Machine Learning, Developing Data Products\n",
      "\n",
      "Dear Terrence Coleman,\n",
      "\n",
      "Thank you for expressing interest in the data scientist role at our company. We would like to invite you to come in for an interview at our Brooklyn office.\n",
      "\n",
      "During the interview, we will be evaluating your skills and experience in predictive modeling and insight reporting. We would also like to get to know you better as a person and learn about your motivations for pursuing a career in data science.\n",
      "\n",
      "Please let us know if you have any questions or concerns. We look forward to meeting you soon.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your name]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interview Scheduling\n",
    "def interview_scheduling(text):\n",
    "    prompt = \"Please generate an interview scheduling email for the candidate and mention\\\n",
    "            a brief introduction to our company and the data scientist role:\"\n",
    "    return interact_with_gpt3(prompt, text)\n",
    "for pdf_file in pdf_files:\n",
    "    interview_mail = interview_scheduling(text)\n",
    "    print(f\"Generated interview scheduling {pdf_file}:\\n{interview_mail}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9656f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def chatbot(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",  # Use the appropriate engine ID\n",
    "        prompt=prompt,\n",
    "        max_tokens=150,\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ed344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! I'm your HR chatbot. How can I assist you with these resumes?\n",
      "You: Give me only names of candidates\n",
      "Chatbot: Candidates:\n",
      "\n",
      "1. Terrence Coleman\n",
      "2. Trish Mathers\n",
      "3. Yasmin Patel\n",
      "4. Kandace Loudor\n",
      "5. Ambrose Horvath\n",
      "You: Give me name of candidate who is having skills like python, machine learning algorithm, data analysis and MySql\n",
      "Chatbot: Kanthi Wagleton\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "Contact:\n",
      "\n",
      "kanthi.wagleton@email.com\n",
      "\n",
      "(123) 456-7890\n",
      "\n",
      "Skills:\n",
      "\n",
      "Python (NumPy, Pandas, Scikit-learn, Keras, TensorFlow), SQL, Tableau, Machine Learning, Deep Learning, Data Visualization\n",
      "\n",
      "Experience:\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "Inﬁnite Analytics\n",
      "\n",
      "June 2019 - present\n",
      "\n",
      "San Francisco, CA\n",
      "\n",
      "● Led a team of 4 data scientists in building predictive models for retail sales data, resulting in a lift in ROI of 10 basis points\n",
      "\n",
      "● Implemented various time series forecasting techniques to\n",
      "You: candidate's name and contact information who is having maximum work experience\n",
      "Chatbot: Candidate: Trish Mathers\n",
      "Contact information: tmathers@email.com, (123) 456-7890\n",
      "\n",
      "Trish Mathers is a recent graduate with a strong background in computer science and data analytics. She has interned at Niantic, where she developed a program that automated the refinement of linear regression models. Trish is also experienced in working with statistical software such as SAS and Excel, and is proficient in using SQL to extract and clean data.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot: Hi! I'm your HR chatbot. How can I assist you with these resumes?\")\n",
    "\n",
    "folder_path = 'ds sample resumes'\n",
    "pdf_files = [file for file in os.listdir(folder_path) if file.endswith('.pdf')]\n",
    "\n",
    "# Concatenate all resume texts into one string\n",
    "all_resume_text = \"\"\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(folder_path, pdf_file)\n",
    "    resume_text = text_extraction(pdf_path)\n",
    "    all_resume_text += resume_text + \"\\n\\n\"\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Chatbot: Exiting the chatbot.\")\n",
    "        break\n",
    "    else:\n",
    "        # Combine user input and all resume texts as the prompt\n",
    "        prompt = f\"You: {user_input}\\nResumes:\\n{all_resume_text}\"\n",
    "        bot_response = chatbot(prompt)\n",
    "        print(f\"Chatbot: {bot_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d9906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
